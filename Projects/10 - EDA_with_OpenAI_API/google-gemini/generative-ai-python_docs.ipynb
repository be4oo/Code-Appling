{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/google-gemini/generative-ai-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! I'll provide you with comprehensive information about the Google Generative AI Python package, including its methods, usage examples, and important tips.\n",
    "\n",
    "Package: google.generativeai (google-generativeai)\n",
    "\n",
    "This is the official Python library for interacting with Google's Generative AI models, including the Gemini family of models.\n",
    "\n",
    "Installation:\n",
    "```\n",
    "pip install google-generativeai\n",
    "```\n",
    "\n",
    "Key Components:\n",
    "\n",
    "1. Configuration:\n",
    "   - You need an API key from Google AI Studio (https://makersuite.google.com/app/apikey)\n",
    "   - Set up the API key:\n",
    "     ```python\n",
    "     import google.generativeai as genai\n",
    "     \n",
    "     genai.configure(api_key='YOUR_API_KEY')\n",
    "     ```\n",
    "\n",
    "2. Main Classes and Methods:\n",
    "\n",
    "   a. GenerativeModel:\n",
    "      - get_model(): Get a specific model\n",
    "      - list_models(): List available models\n",
    "      - generate_content(): Generate content from a prompt\n",
    "      - start_chat(): Start a chat session\n",
    "      - count_tokens(): Count tokens in a prompt\n",
    "\n",
    "   b. ChatSession:\n",
    "      - send_message(): Send a message in a chat session\n",
    "      - rewind(): Rewind the chat history\n",
    "\n",
    "   c. Content:\n",
    "      - text: Access generated text\n",
    "      - parts: Access multi-modal content parts\n",
    "\n",
    "3. Example Usage:\n",
    "\n",
    "   a. Text Generation:\n",
    "   ```python\n",
    "   model = genai.GenerativeModel('gemini-pro')\n",
    "   response = model.generate_content(\"Explain quantum computing in simple terms.\")\n",
    "   print(response.text)\n",
    "   ```\n",
    "\n",
    "   b. Chat:\n",
    "   ```python\n",
    "   chat = model.start_chat(history=[])\n",
    "   response = chat.send_message(\"Hello, how are you?\")\n",
    "   print(response.text)\n",
    "   ```\n",
    "\n",
    "   c. Multi-modal Input (Text + Image):\n",
    "   ```python\n",
    "   from PIL import Image\n",
    "\n",
    "   model = genai.GenerativeModel('gemini-pro-vision')\n",
    "   img = Image.open('image.jpg')\n",
    "   response = model.generate_content([\"Describe this image\", img])\n",
    "   print(response.text)\n",
    "   ```\n",
    "\n",
    "4. Safety Settings:\n",
    "   - You can adjust safety settings for content filtering:\n",
    "   ```python\n",
    "   model = genai.GenerativeModel('gemini-pro',\n",
    "       safety_settings=[\n",
    "           {\n",
    "               \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
    "               \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "           },\n",
    "       ]\n",
    "   )\n",
    "   ```\n",
    "\n",
    "5. Streaming Responses:\n",
    "   ```python\n",
    "   response = model.generate_content(\"Write a story about a robot.\", stream=True)\n",
    "   for chunk in response:\n",
    "       print(chunk.text, end='', flush=True)\n",
    "   ```\n",
    "\n",
    "6. Error Handling:\n",
    "   ```python\n",
    "   try:\n",
    "       response = model.generate_content(\"Prompt\")\n",
    "       if response.prompt_feedback.block_reason:\n",
    "           print(\"Response was blocked:\", response.prompt_feedback.block_reason)\n",
    "       else:\n",
    "           print(response.text)\n",
    "   except genai.types.generation_types.BlockedPromptException as e:\n",
    "       print(\"Prompt was blocked:\", e.message)\n",
    "   ```\n",
    "\n",
    "Tips:\n",
    "\n",
    "1. Token Limits: Be aware of token limits for different models. Use `count_tokens()` to check.\n",
    "2. API Key Security: Never hardcode your API key. Use environment variables or secure storage.\n",
    "3. Rate Limiting: Be mindful of API rate limits and implement appropriate error handling.\n",
    "4. Model Selection: Choose the appropriate model for your task (e.g., 'gemini-pro' for text, 'gemini-pro-vision' for multi-modal).\n",
    "5. Prompt Engineering: Craft clear and specific prompts for better results.\n",
    "6. Content Moderation: Use safety settings to filter inappropriate content.\n",
    "7. Streaming: Use streaming for long-form content generation to get partial results quickly.\n",
    "8. Error Handling: Implement robust error handling, especially for blocked content and API issues.\n",
    "9. Keep Updated: The library is actively developed, so keep it updated and check the official documentation for the latest features and best practices.\n",
    "\n",
    "For the most up-to-date and detailed information, always refer to the official documentation:\n",
    "https://ai.google.dev/tutorials/python_quickstart\n",
    "\n",
    "This package is powerful and versatile, allowing you to leverage Google's advanced AI models for various generative AI tasks in your Python applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
